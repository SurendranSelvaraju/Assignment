---
title: "Assigment"
author: "Surendran"
date: "November 19, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.

In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

Data

The training data for this project are downloaded from: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are downloaded from: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

It is worth citing Groupware@LES for being generous in allowing their data to be used for this assignment.

Goal of the assignment

-Predicting the manner in which the participants did the exercise. Refer to the "classe" variable in the training set. All other variables can be used as predictor.

-Show how the model was built, performed cross validation, and expectation of the sample error and reasons of choices made.

-Use the prediction model to predict 20 different test cases.

Data Preprocessing
```{r}
library(caret)
library(rpart)
library(knitr)
library(randomForest)
library(ElemStatLearn)
library(corrplot)
set.seed(888)
```


Preparation of data
```{r}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile)
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile)
}
```


Read data
```{r}
trainRaw <- read.csv("./data/pml-training.csv",header=T,sep=",",na.strings=c("NA",""))
testRaw <- read.csv("./data/pml-testing.csv",header=T,sep=",",na.strings=c("NA",""))
dim(trainRaw)
```


```{r}
dim(testRaw)
```
The training data set comprise of 19622 observations and 160 variables, while the testing data set comprise of 20 observations and 160 variables. The outcome that need to be predicted is the variable in the training set which is "classe".



Data Sets Partitioning Definitions



```{r}
trainRaw <- trainRaw[,-1]
inTrain = createDataPartition(trainRaw$classe, p=0.60, list=F)
training = trainRaw[inTrain,]
validating = trainRaw[-inTrain,]
```



Data cleaning

The data set is checked on with the possibility of columns without data. The decision is made whereby all the columns that having less than 60% of data filled are removed.


```{r}
sum((colSums(!is.na(training[,-ncol(training)])) < 0.6*nrow(training)))
```
Next step is removing the columns that are not favourable before creating a model.

```{r}
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.6*nrow(training)))
training   <-  training[,Keep]
validating <- validating[,Keep]
```

Modeling
In random forests, there is no need for cross-validation or a separate test set to get an unbiased estimate of the test set error. It is estimated internally, during the execution. Therefore, the training of the model (Random Forest) is proceeded using the training data set.

```{r}
model <- randomForest(classe~.,data=training)
model
```




Model Evaluation

Each variable with its measure that produce by random Forest model is verified

```{r}
importance(model)
```

Confuxion Matrix is used to further evaluate the model results.

```{r}
confusionMatrix(predict(model,newdata=validating[,-ncol(validating)]),validating$classe)
```


Formula is used to calculate the accuracy for teh validating data set.

```{r}
acrcy<-c(as.numeric(predict(model,newdata=validating[,-ncol(validating)])==validating$classe))
acrcy<-sum(acrcy)*100/nrow(validating)
```



Model Accuracy as tested over Validation set whereby it produce 99.8725465% of accuracy and the out-of-sample error is 0.13%, which is small.



Model test
```{r}

testRaw <- testRaw[,-1] 
testRaw <- testRaw[ , Keep] 
testRaw <- testRaw[,-ncol(testRaw)]
```


Transformations and Coercing of Testing Dataset

 
```{r}
testing <- rbind(training[100, -59] , testRaw) 
row.names(testing)
```

Prediction with the Testing Dataset

```{r}
predictions <- predict(model,newdata=testing[-1,])
predictions

```


Generation of Answers Files for Assignment Submission
The following function pml_write_files is to create the answers files for the Prediction Assignment Submission:


```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./answer/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictions)

```
```























